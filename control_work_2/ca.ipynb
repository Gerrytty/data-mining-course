{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "unique-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json\n",
    "import pymorphy2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "included-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data = pd.read_csv(\"Corona_NLP_train.csv\", encoding = \"ISO-8859-1\")\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-discrimination",
   "metadata": {},
   "source": [
    "Для начала немного преподготовим наши данные, и объеденим Extremely Negative с Negative  \n",
    "и Extremely Positive с Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data.loc[twitter_data.Sentiment == 'Extremely Negative', 'Sentiment'] = 'Negative'\n",
    "twitter_data.loc[twitter_data.Sentiment == 'Extremely Positive', 'Sentiment'] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norman-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   Neutral  \n",
       "1  advice Talk to your neighbours family to excha...  Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...  Positive  \n",
       "3  My food stock is not the only one which is emp...  Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-locking",
   "metadata": {},
   "source": [
    "Теперь очистим данные от хэштегов, ссылок и прочего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compact-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    out = []\n",
    "    for i in range(0, len(data)):\n",
    "        temp = data[i]\n",
    "        temp = re.sub(\"@\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"https*\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"#\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"\\'\\w+\", '', temp)\n",
    "        temp = re.sub('[%s]' % re.escape(string.punctuation), ' ', temp)\n",
    "        temp = re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "        temp = re.sub('\\s{2,}', \" \", temp)\n",
    "        list_of_temp = temp.split(\" \")\n",
    "        list_of_temp = list(map(lambda x: x.lower(), list_of_temp))\n",
    "        temp = ' '.join(list_of_temp)\n",
    "        out.append(temp)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "optimum-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = clean(list(twitter_data['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-things",
   "metadata": {},
   "source": [
    "Создадим новый датасет, с которым и будем работать в будущем.  \n",
    "Для определения тональности текста нам не понадобятся username, ScreenName, Location, TweetAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "postal-sally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and and</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me ready to go at supermarket during the outbr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0                                           and and    Neutral\n",
       "1  advice talk to your neighbours family to excha...  Positive\n",
       "2  coronavirus australia woolworths to give elder...  Positive\n",
       "3  my food stock is not the only one which is emp...  Positive\n",
       "4  me ready to go at supermarket during the outbr...  Negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_twitts = pd.DataFrame()\n",
    "\n",
    "clean_twitts['OriginalTweet'] = out\n",
    "clean_twitts['Sentiment'] = twitter_data['Sentiment']\n",
    "\n",
    "clean_twitts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optical-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Positive', 'Negative']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим какие классы у нас вообще есть\n",
    "list_of_labels = list(clean_twitts['Sentiment'].unique())\n",
    "list_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "still-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разделяет твитты по классам и записывает их в файл, нужно мне для анализа в amazon comprehend\n",
    "def get_twitts(twitter_data, label, filename):\n",
    "    l = twitter_data[twitter_data.Sentiment == label]\n",
    "    l = list(l['OriginalTweet'])\n",
    "    \n",
    "    f = open(f\"{filename}.txt\", \"w\")\n",
    "    for twitt in l[0:int(len(l)/10)]:\n",
    "        f.write(twitt + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "saved-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим файл для каждого класса\n",
    "# в результате у нас есть три файла\n",
    "# в каждом файле-классе только твитты относящиеся к этому классу\n",
    "for label in list_of_labels:\n",
    "    get_twitts(clean_twitts, label, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-bouquet",
   "metadata": {},
   "source": [
    "Далее а Amazon Comprehend я для каждого файла сделала анализ на Sentiment, по строчно.  \n",
    "Так как у меня в каждом файле хранятся твитты (разделенные новой строкой), относящиеся только к классу с названием файла, метрику accuracy можно посчитать следующим образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "applied-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(filename, clean=False):\n",
    "    jsons = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            jsons.append(json.loads(line))\n",
    "    \n",
    "    score = 0\n",
    "    for j in jsons:\n",
    "        # сравниваю название файла с предсказаной тональностью (должны совпадать)\n",
    "        original_sentiment = j['File'].split(\".\")[0].lower()\n",
    "        if clean:\n",
    "            original_sentiment = original_sentiment.split(\"_\")[0]\n",
    "        pred_sentiment = j['Sentiment'].lower()\n",
    "        if original_sentiment == pred_sentiment:\n",
    "            score += 1\n",
    "                        \n",
    "    return score / len(jsons) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-color",
   "metadata": {},
   "source": [
    "Как мы видим с помощью амазон сервиса мы получили крайне низкий результат accuracy  \n",
    "Лишь немного выше чем рандомный выбор с вероятностью угадать 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "negative-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 39.499270782693245%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(\"sentiment_from_comprehend.txt\")\n",
    "print(f\"Accuracy = {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-making",
   "metadata": {},
   "source": [
    "Теперь попробуем всё тоже самое, только удалим стоп-слова и преобразуем все слова в начальную форму.  \n",
    "Для этого создадим ещё один датафрейм, потому что тот нам еще понадобится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "broken-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем в начальную форму и удаляем стоп-слова\n",
    "\n",
    "list_of_twitts = list(twitter_data['OriginalTweet'])\n",
    "out_list = []\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "for twitt in list_of_twitts:\n",
    "    # удаляем стоп-слова\n",
    "    filtered_words = [word for word in twitt.split(\" \") if word not in stopwords.words('english')]\n",
    "    # преобразуем в начальную форму\n",
    "    normal_form_words = []\n",
    "    for word in filtered_words:\n",
    "        normal_form_words.append(morph.parse(word)[0].normal_form)\n",
    "    # объединяем\n",
    "    out_list.append(' '.join(normal_form_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "excessive-purchase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@menyrbie @phil_gahan @chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my food stock one empty...\\r\\r\\n\\r\\r\\nplease, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me, ready go supermarket #covid19 outbreak.\\r\\...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  @menyrbie @phil_gahan @chrisitv https://t.co/i...   Neutral\n",
       "1  advice talk neighbours family exchange phone n...  Positive\n",
       "2  coronavirus australia: woolworths give elderly...  Positive\n",
       "3  my food stock one empty...\\r\\r\\n\\r\\r\\nplease, ...  Positive\n",
       "4  me, ready go supermarket #covid19 outbreak.\\r\\...  Negative"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_normal = pd.DataFrame()\n",
    "\n",
    "clean_and_normal['OriginalTweet'] = out_list\n",
    "clean_and_normal['Sentiment'] = twitter_data['Sentiment']\n",
    "\n",
    "clean_and_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "orange-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим такие же файлы как и раньше\n",
    "for label in list_of_labels:\n",
    "    get_twitts(clean_and_normal, label, label + '_cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-campus",
   "metadata": {},
   "source": [
    "Далее всё тоже самое с Amazon Comprehend  \n",
    "Как можно наблюдать точность уменьшилась, что меня несколько удивило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cooked-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 31.40495867768595%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(\"sentiment_from_comprehend_clean_data.txt\", True)\n",
    "print(f\"Accuracy = {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-seven",
   "metadata": {},
   "source": [
    "Теперь попробуем написать что-то своё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acquired-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нам нужна функция которая посчитает метрику accuracy схожим способом что и раньше\n",
    "def get_accuracy_from_list(real, predictions):\n",
    "    score = 0\n",
    "    for i in range(len(real)):\n",
    "        if real[i] == predictions[i]:\n",
    "            score += 1\n",
    "    return score / len(real) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-steering",
   "metadata": {},
   "source": [
    "Далее поделим наши данные на тестовую и обучающие выборки, сначала для данных, очищенных только от хэштегов, ссылок и прочего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "antique-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_twitts['OriginalTweet'], clean_twitts['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-frame",
   "metadata": {},
   "source": [
    "Преобразуем данные в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adequate-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "immune-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(list(X_train)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "brilliant-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), train_data_features, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-sucking",
   "metadata": {},
   "source": [
    "Как можно наблюдать даже простая логистическая регрессия справилась с нашей задачей куда лучаше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "lonely-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-ticket",
   "metadata": {},
   "source": [
    "Всё тоже самое, только для нормализованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "altered-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_and_normal['OriginalTweet'], clean_and_normal['Sentiment'], test_size=0.2, random_state=42)\n",
    "train_data_features = vectorizer.fit_transform(list(X_train)).toarray()\n",
    "scores = cross_val_score(LogisticRegression(), train_data_features, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "subject-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-explanation",
   "metadata": {},
   "source": [
    "С RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "statistical-dayton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "train_data_features = vectorizer.fit_transform(list(X_train)).toarray()\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators = 200), train_data_features, y_train, cv=5)\n",
    "print(\"Accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
