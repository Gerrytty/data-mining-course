{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "conservative-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json\n",
    "import pymorphy2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acknowledged-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv(\"Corona_NLP_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "white-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-lending",
   "metadata": {},
   "source": [
    "Для начала немного преподготовим наши данные, и объеденим Extremely Negative с Negative  \n",
    "и Extremely Positive с Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "excess-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-9eae80cfb354>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twitter_data['Sentiment'][i]='Negative'\n",
      "<ipython-input-39-9eae80cfb354>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twitter_data['Sentiment'][i]='Positive'\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(twitter_data)):\n",
    "    if(twitter_data['Sentiment'][i] == 'Extremely Negative'):\n",
    "        twitter_data['Sentiment'][i] = 'Negative'\n",
    "    elif(twitter_data['Sentiment'][i] == 'Extremely Positive'):\n",
    "        twitter_data['Sentiment'][i] = 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-thompson",
   "metadata": {},
   "source": [
    "Теперь очистим данные от хэштегов, ссылок и прочего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fatty-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    out = []\n",
    "    for i in range(0, len(data)):\n",
    "        temp = data[i]\n",
    "        temp = re.sub(\"@\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"https*\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"#\\S+\", \" \", temp)\n",
    "        temp = re.sub(\"\\'\\w+\", '', temp)\n",
    "        temp = re.sub('[%s]' % re.escape(string.punctuation), ' ', temp)\n",
    "        temp = re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "        temp = re.sub('\\s{2,}', \" \", temp)\n",
    "        list_of_temp = temp.split(\" \")\n",
    "        list_of_temp = list(map(lambda x: x.lower(), list_of_temp))\n",
    "        temp = ' '.join(list_of_temp)\n",
    "        out.append(temp)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hydraulic-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_data(out):\n",
    "    twitter_data.drop(['OriginalTweet'], axis=1)\n",
    "    twitter_data['OriginalTweet'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dangerous-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = clean(list(twitter_data['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "informal-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_data(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "plain-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>and and</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me ready to go at supermarket during the outbr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0                                           and and    Neutral  \n",
       "1  advice talk to your neighbours family to excha...  Positive  \n",
       "2  coronavirus australia woolworths to give elder...  Positive  \n",
       "3  my food stock is not the only one which is emp...  Positive  \n",
       "4  me ready to go at supermarket during the outbr...  Negative  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-reception",
   "metadata": {},
   "source": [
    "Теперь поделим наш датасет на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "variable-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Positive', 'Negative']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_labels = list(twitter_data['Sentiment'].unique())\n",
    "list_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "powerful-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitts(label, filename):\n",
    "    l = twitter_data[twitter_data.Sentiment == label]\n",
    "    l = list(l['OriginalTweet'])\n",
    "    \n",
    "    f = open(f\"{filename}.txt\", \"w\")\n",
    "    for twitt in l[0:int(len(l)/10)]:\n",
    "        f.write(twitt + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "light-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in list_of_labels:\n",
    "    get_twitts(label, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "controversial-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehendDetect:\n",
    "    def __init__(self, comprehend_client):\n",
    "        self.comprehend_client = comprehend_client\n",
    "\n",
    "    def detect_key_phrases(self, text, language_code):\n",
    "        try:\n",
    "            response = self.comprehend_client.detect_key_phrases(\n",
    "                Text=text, LanguageCode=language_code)\n",
    "            phrases = response['KeyPhrases']\n",
    "        except ClientError:\n",
    "            raise\n",
    "        else:\n",
    "            return phrases\n",
    "\n",
    "    def detect_sentiment(self, text, language_code):\n",
    "        try:\n",
    "            response = self.comprehend_client.detect_sentiment(\n",
    "                Text=text, LanguageCode=language_code)\n",
    "        except ClientError:\n",
    "            raise\n",
    "        else:\n",
    "            return response\n",
    "        \n",
    "access_key_id = os.getenv('MY_ACCESS_KEY_ID')\n",
    "secret_access_key = os.getenv('MY_SECRET_ACCESS_KEY')\n",
    "comp = boto3.client('comprehend', region_name=\"us-east-1\", aws_session_token = \"IQoJb3JpZ2luX2VjEN3//////////wEaCXVzLXdlc3QtMiJIMEYCIQDwDaa3iRyHxfv1/17JkOINlWpmcYr8v0T89LUbq+af+gIhALkPo+Zjl6fiPWArPkfYHs3la8SqhhsKRZpC7X4eMacgKrQCCGYQABoMNjEzMjg5NjM4NDE4Igxk84kQHvp/EPLx0YQqkQKEgMceKtfS+4ir5IrcKS5P1OHWkacRYULVcjJ5jiHI0cBdzc1IiCPoTtHrA2tvHPjbevT5d5SAwDqCKSoruYradaJJ9jQa94BkfUGaoXlGLDJETg/wvS9d4Ae+vyZiMN/+FjmB7DoTRlWbxk/Z/+bnWJrUXptHv2xCNPqowUsGyPdSbe2NYj1tpBXjk7SPu1przhlOinnMaQQWPrMKLmhFrhrisQLi0rUPLsUOkK6hEfRATEuO0yLPN29DCzpqhheRNINxwP99yv3qV3dLsREQj3umsuH65iLV9W1ECM3tGNgGXsfaGKbMGSM89wk3OFCWa0KP/la66TYSHmuMg/M3d7J8p+cohTIvfa9AbkgnYUQwk+zbhAY6nAEaU9q43L2UGV0hQrDqmk11anPqSK5QH1G9KdsVpGlLPmnvrxIeGIVfeRV3qrdxrZyjOlrk+B9/mymhNSr5z6uM8QNhfC5spHQXb67wUVmjdHWFf55FpcwDuH+a4xsVHBSutN9k4kP2gGeD4ttgCoAA7XdOqaIbb7Yjk5iN0r48G1lUEPue4vvpWgHE/ax3mW7IW0UwgdR0hEPbIsc=\")\n",
    "\n",
    "comp_detect = ComprehendDetect(comp)\n",
    "\n",
    "phrases = comp_detect.detect_key_phrases('', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "consolidated-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(filename, clean=False):\n",
    "    jsons = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            jsons.append(json.loads(line))\n",
    "    \n",
    "    score = 0\n",
    "    for j in jsons:\n",
    "        original_sentiment = j['File'].split(\".\")[0].lower()\n",
    "        if clean:\n",
    "            original_sentiment = original_sentiment.split(\"_\")[0]\n",
    "        pred_sentiment = j['Sentiment'].lower()\n",
    "        if original_sentiment == pred_sentiment:\n",
    "            score += 1\n",
    "                        \n",
    "    return score / len(jsons) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-certificate",
   "metadata": {},
   "source": [
    "Как мы видим с помощью амазон сервиса мы получили крайне низкий результат accuracy  \n",
    "Лишь немного выше чем рандомный выбор с вероятностью угадать 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "narrow-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 39.499270782693245%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(\"sentiment_from_comprehend.txt\")\n",
    "print(f\"Accuracy = {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-gallery",
   "metadata": {},
   "source": [
    "Теперь попробуем всё тоже самое, только удалим стоп-слова и преобразуем все слова в начальную форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "casual-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "## если не скачено\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "novel-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_twitts = list(twitter_data['OriginalTweet'])\n",
    "out_list = []\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "for twitt in list_of_twitts:\n",
    "    # удаляем стоп-слова\n",
    "    filtered_words = [word for word in twitt.split(\" \") if word not in stopwords.words('english')]\n",
    "    # преобразуем в начальную форму\n",
    "    normal_form_words = []\n",
    "    for word in filtered_words:\n",
    "        normal_form_words.append(morph.parse(word)[0].normal_form)\n",
    "    # объединяем\n",
    "    out_list.append(' '.join(normal_form_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "rubber-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменяем данные на очищенные\n",
    "replace_data(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accomplished-television",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths give elderly ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ready go supermarket outbreak paranoid food st...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0                                                      Neutral  \n",
       "1  advice talk neighbours family exchange phone n...  Positive  \n",
       "2  coronavirus australia woolworths give elderly ...  Positive  \n",
       "3  food stock one empty please panic enough food ...  Positive  \n",
       "4  ready go supermarket outbreak paranoid food st...  Negative  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ahead-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in list_of_labels:\n",
    "    get_twitts(label, label + '_cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-official",
   "metadata": {},
   "source": [
    "Как можно наблюдать точность уменьшилась, что меня несколько удивило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "orange-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 31.40495867768595%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(\"sentiment_from_comprehend_clean_data.txt\", True)\n",
    "print(f\"Accuracy = {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "acting-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(twitter_data['OriginalTweet'], twitter_data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "union-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)\n",
    "\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(list(twitter_data['OriginalTweet'])).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "transparent-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41157, 6)\n",
      "(41157, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data.shape)\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "normal-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit(train_data_features[:30000], list(twitter_data['Sentiment'])[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "sitting-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Positive' 'Positive' ... 'Positive' 'Positive' 'Negative']\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(train_data_features[30000:])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "israeli-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_list(real, predictions):\n",
    "    score = 0\n",
    "    for i in range(len(real)):\n",
    "        if real[i] == predictions[i]:\n",
    "            score += 1\n",
    "    return score / len(real) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-armor",
   "metadata": {},
   "source": [
    "С помощью этого метада мы получили уже куда большую точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "affected-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 76.57972573272384%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy_from_list(list(twitter_data[\"Sentiment\"])[30000:], predictions)\n",
    "print(f\"Accuracy = {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-alfred",
   "metadata": {},
   "source": [
    "Теперь попробуем воспользоваться методом word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-central",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
